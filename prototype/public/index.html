<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ReMic — Audio-only WebRTC (QR Auto Flow)</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <main>
    <h1>ReMic — Audio-only WebRTC</h1>
    <!-- Legacy manual controls (kept for fallback) -->
    <section class="controls">
      <label>Room <input id="room" placeholder="e.g. remic-voice-001"></label>
      <button id="join">Join</button>
      <button id="start" disabled>Start Call</button>
      <button id="hangup" disabled>Hang Up</button>
      <p id="status">Status: idle</p>
      <div class="ai-controls">
        <label><input type="checkbox" id="toggleInterpret" checked> Interpretation</label>
        <label><input type="checkbox" id="toggleMonitor"> Monitor AI Audio</label>
        <span id="aiState" style="margin-left:8px;font-size:0.9em;opacity:0.8;">AI: idle</span>
      </div>
    </section>

    <!-- New auto pairing flow overlay -->
    <div id="flow" class="overlay">
      <div class="lang-select" id="langSelect">
        <h2>Pick your language</h2>
        <div class="lang-buttons">
          <button data-lang="zh">中文 Chinese</button>
          <button data-lang="en">English 英文</button>
        </div>
        <p class="small-note">We'll create a private audio room and show a QR code. Scan it with another device to connect instantly.</p>
      </div>
      <div class="qr-stage hidden" id="qrStage">
        <h2 id="langChosen"></h2>
        <div id="qr">Generating…</div>
        <div class="qr-meta" id="qrMeta"></div>
        <a class="scan-link" id="enterScan" href="#scan">Scan Other's</a>
        <div class="scan-view" id="scanView">
          <video id="scanVideo" class="scan" playsinline muted></video>
          <div class="qr-meta">Point your camera at the other device's QR code…</div>
          <button id="cancelScan" style="margin-top:4px;">Cancel</button>
        </div>
      </div>
    </div>

    <section class="audio">
      <div>
        <h3>Local Mic</h3>
        <audio id="local" autoplay muted></audio>
      </div>
      <div>
        <h3>Remote Audio</h3>
        <audio id="remote" autoplay></audio>
      </div>
      <div style="display:none" id="aiMonitorWrap">
        <h3>AI Output</h3>
        <audio id="aiMonitor" autoplay></audio>
      </div>
    </section>

    <section class="notes">
      <ul>
        <li>Automatic QR pairing flow active.</li>
        <li>Audio-only, mono Opus, low bitrate, ptime=10, DTX on.</li>
      </ul>
    </section>
    <section id="debugPanel" class="hidden" style="font-family:monospace; font-size:12px; max-height:260px; overflow:auto; background:#111;">
      <strong>ICE Debug</strong>
      <div id="iceStates" style="margin-top:4px; opacity:.8;"></div>
      <div style="display:flex; gap:12px; margin-top:6px;">
        <div style="flex:1;">
          <div style="font-weight:600;">Local Candidates</div>
          <ul id="localCands" style="margin:4px 0 0; padding-left:16px;"></ul>
        </div>
        <div style="flex:1;">
          <div style="font-weight:600;">Remote Candidates</div>
          <ul id="remoteCands" style="margin:4px 0 0; padding-left:16px;"></ul>
        </div>
      </div>
      <div style="margin-top:6px;">
        <div style="font-weight:600;">Selected Pair</div>
        <pre id="selectedPair" style="white-space:pre-wrap; margin:4px 0 0; background:#0b0b0b; padding:6px; border-radius:6px;"></pre>
      </div>
    </section>
  </main>

  <script>
    const $ = (id) => document.getElementById(id);
    const roomEl = $('room'), joinBtn = $('join'), startBtn = $('start'), hangupBtn = $('hangup');
    const statusEl = $('status'), localEl = $('local'), remoteEl = $('remote');
    const interpretChk = $('toggleInterpret'), monitorChk = $('toggleMonitor');
    const aiStateEl = $('aiState'), aiMonitorEl = $('aiMonitor'), aiMonitorWrap = $('aiMonitorWrap');
    // New flow elements
    const flow = $('flow');
    const langSelect = $('langSelect');
    const qrStage = $('qrStage');
    const langChosenEl = $('langChosen');
    const qrEl = $('qr');
    const qrMetaEl = $('qrMeta');
    const enterScan = $('enterScan');
    const scanView = $('scanView');
    const scanVideo = $('scanVideo');
    const cancelScanBtn = $('cancelScan');

    const proto = location.protocol === 'https:' ? 'wss' : 'ws';
    const wsURL = `${proto}://${location.host}`;
    let ws, room;
    let chosenLang = null;
    let isScanner = false; // user B when scanning or arriving with ?room
  // WebRTC state vars
  let pc, localStream, remoteStream;
  let aiPc = null;           // AI interpretation PeerConnection
  let aiSessionPromise;      // Promise for AI setup
  let aiActive = false;      // Is interpreted track active
  let originalTrack = null;  // Original mic track
  let currentSender = null;  // RTCRtpSender of outbound audio
  let aiReturnedTrack = null;// Interpreted audio track
    // Debugging structures
    const localCandList = [];
    const remoteCandList = [];
    const localCandsEl = document.getElementById('localCands');
    const remoteCandsEl = document.getElementById('remoteCands');
    const iceStatesEl = document.getElementById('iceStates');
    const selectedPairEl = document.getElementById('selectedPair');
    const debugPanel = document.getElementById('debugPanel');

    function setStatus(s) { statusEl.textContent = 'Status: ' + s; console.log('[status]', s); }
    function setAIState(s) { aiStateEl.textContent = 'AI: ' + s; console.log('[ai]', s); }

    // Simple toast system
    let toastTimer;
    function showToast(msg, type='info') {
      let el = document.getElementById('toast');
      if (!el) {
        el = document.createElement('div');
        el.id = 'toast';
        Object.assign(el.style, { position:'fixed', bottom:'12px', right:'12px', background:'#222', color:'#fff', padding:'8px 12px', borderRadius:'6px', fontSize:'14px', maxWidth:'260px', zIndex:9999, boxShadow:'0 2px 8px rgba(0,0,0,0.3)', transition:'opacity .3s' });
        document.body.appendChild(el);
      }
      el.style.opacity = 1;
      el.style.background = type==='error' ? '#b3261e' : (type==='warn' ? '#b26f1e' : '#222');
      el.textContent = msg;
      clearTimeout(toastTimer);
      toastTimer = setTimeout(()=>{ el.style.opacity = 0; }, 4000);
    }

    function send(type, data) { ws?.send(JSON.stringify({ type, ...(data||{}) })); }

    async function connectWS() {
      if (ws && ws.readyState === WebSocket.OPEN) return;
      ws = new WebSocket(wsURL);
      await new Promise((res, rej) => { ws.onopen = res; ws.onerror = rej; });
      ws.onmessage = async (ev) => {
        const m = JSON.parse(ev.data);
        if (m.type === 'joined') {
          setStatus('joined room'); startBtn.disabled = false;
        }
        else if (m.type === 'peer-joined') {
          setStatus('peer joined');
          if (document.body.classList.contains('auto-flow')) {
            if (!pc && !isScanner) { startCall(); }
          }
        }
        else if (m.type === 'peer-left') { setStatus('peer left'); endCall(); }
        else if (m.type === 'signal') { await handleSignal(m.data); }
      };
    }

    // --- ICE / TURN config ---
    const iceServers = [
      { urls: ['stun:stun.l.google.com:19302'] },
      {
        urls: [
          'turn:138.68.22.130:3478?transport=udp',
          'turn:138.68.22.130:3478?transport=tcp'
        ],
        username: 'alice',
        credential: 'secret'
      }
    ];
    const params = new URLSearchParams(location.search);
  let forceRelay = params.get('forcerelay') === '1';
  const showDebug = forceRelay || params.get('debug') === '1';
    if (showDebug) debugPanel.classList.remove('hidden');

  function ensurePC() {
      if (pc) return pc;
      const cfg = { iceServers };
      if (forceRelay) cfg.iceTransportPolicy = 'relay';
      pc = new RTCPeerConnection(cfg);
      pc.onicecandidate = (e) => {
        if (e.candidate) {
          console.log('[ice] local cand', e.candidate.candidate);
          localCandList.push(e.candidate.candidate);
          if (showDebug) { const li = document.createElement('li'); li.textContent = e.candidate.candidate; localCandsEl.appendChild(li); }
          send('signal', { data: { candidate: e.candidate } });
        } else {
          console.log('[ice] candidate gathering complete');
        }
      };
      pc.onicecandidateerror = (e) => { console.warn('[ice] candidate error', e.errorText || e); };
      pc.oniceconnectionstatechange = () => {
        console.log('[ice] state', pc.iceConnectionState);
        if (showDebug) iceStatesEl.textContent = 'iceConnectionState=' + pc.iceConnectionState + '  connectionState=' + pc.connectionState;
        if (pc.iceConnectionState === 'failed') {
          dumpSelectedCandidatePair();
          if (!forceRelay) {
            console.warn('[ice] escalating to TURN-relay only and retrying');
            escalateToRelay();
          }
        }
      };
      pc.onconnectionstatechange = () => { setStatus('pc: ' + pc.connectionState); if (pc.connectionState === 'failed') dumpSelectedCandidatePair(); };
      pc.onsignalingstatechange = () => console.log('[pc] signaling', pc.signalingState);
      pc.ontrack = (e) => { if (!remoteStream) remoteStream = new MediaStream(); e.streams[0].getAudioTracks().forEach(t => remoteStream.addTrack(t)); remoteEl.srcObject = remoteStream; };
      return pc;
    }

    async function dumpSelectedCandidatePair() {
      if (!pc) return;
      try {
        const stats = await pc.getStats();
        let selected;
        stats.forEach(r => { if (r.type === 'transport' && r.selectedCandidatePairId) selected = stats.get(r.selectedCandidatePairId); });
        if (!selected) stats.forEach(r => { if (r.type === 'candidate-pair' && r.state === 'succeeded') selected = r; });
        if (selected) {
          const local = stats.get(selected.localCandidateId);
            const remote = stats.get(selected.remoteCandidateId);
          const summary = {
            state: selected.state,
            nominated: selected.nominated,
            local: local && { type: local.candidateType, ip: local.ip || local.address, port: local.port, proto: local.protocol },
            remote: remote && { type: remote.candidateType, ip: remote.ip || remote.address, port: remote.port, proto: remote.protocol }
          };
          console.warn('[ice] selected pair', summary);
          if (showDebug) selectedPairEl.textContent = JSON.stringify(summary, null, 2);
        } else {
          console.warn('[ice] no selected pair found');
          if (showDebug) selectedPairEl.textContent = 'No selected candidate pair.';
        }
      } catch (e) { console.warn('[ice] stats error', e); }
    }

    async function getMic() {
      if (localStream) return localStream;
      localStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 48000,
          echoCancellation: true,
            noiseSuppression: true,
          autoGainControl: true
        },
        video: false
      });
      localEl.srcObject = localStream;
      return localStream;
    }

    function tuneOpusSdp(sdp) {
      // Prefer Opus and set params: mono, low bitrate, ptime=10, DTX, FEC.
      sdp = sdp.replace(/a=fmtp:(\d+) (.*)\r\n/g, (m, pt, params) => m); // keep others
      // Force default codec order to Opus first
      sdp = sdp.replace(/m=audio \d+ UDP\/TLS\/RTP\/SAVPF ([0-9 ]+)\r\n/, (m, caps) => {
        const list = caps.trim().split(' ');
        const opusPT = list.find(pt => new RegExp(`a=rtpmap:${pt} opus\\/48000\\/2`).test(sdp) || new RegExp(`a=rtpmap:${pt} opus\\/48000\\/1`).test(sdp));
        if (!opusPT) return m;
        const reordered = [opusPT, ...list.filter(x => x !== opusPT)].join(' ');
        return m.replace(caps, reordered);
      });
      // Add fmtp for opus payloads
      sdp = sdp.replace(/a=rtpmap:(\d+) opus\/48000\/(\d+)\r\n/g, (m, pt, ch) => {
        const fmtp = [
          `a=fmtp:${pt} stereo=0`,
          `sprop-stereo=0`,
          `maxaveragebitrate=24000`,
          `ptime=10`,
          `useinbandfec=1`,
          `usedtx=1`
        ].join(';');
        return `${m}${fmtp}\r\n`;
      });
      return sdp;
    }

    async function startCall() {
      await getMic();
      const pc = ensurePC();
      const micTracks = localStream.getAudioTracks();
      originalTrack = micTracks[0];
      currentSender = pc.addTrack(originalTrack, localStream);
      if (interpretChk.checked) {
        initializeRealtimeConversion().catch(err => {
          showToast('Interpretation failed (fallback mic)', 'warn');
          setAIState('failed');
        });
      } else {
        setAIState('disabled');
      }

  let offer = await pc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
  offer.sdp = tuneOpusSdp(offer.sdp);
  await pc.setLocalDescription(offer);
      send('signal', { data: { sdp: pc.localDescription } });
      startBtn.disabled = true; hangupBtn.disabled = false;
      setStatus('offer sent');
    }

    async function handleSignal(obj) {
      const pc = ensurePC();
      if (obj.sdp) {
        const desc = obj.sdp;
        if (desc.type === 'offer') {
          await getMic();
          const micTracks = localStream.getAudioTracks();
          originalTrack = micTracks[0];
          currentSender = pc.addTrack(originalTrack, localStream);
          if (interpretChk.checked) {
            initializeRealtimeConversion().catch(err => {
              showToast('Interpretation failed (answerer fallback)', 'warn');
              setAIState('failed');
            });
          } else {
            setAIState('disabled');
          }
          await pc.setRemoteDescription(desc);
          let answer = await pc.createAnswer();
          answer.sdp = tuneOpusSdp(answer.sdp);
          await pc.setLocalDescription(answer);
          send('signal', { data: { sdp: pc.localDescription } });
          hangupBtn.disabled = false;
          setStatus('answer sent');
        } else if (desc.type === 'answer') {
          await pc.setRemoteDescription(desc);
          setStatus('answer received');
        }
      } else if (obj.candidate) {
        if (showDebug) {
          const cstr = obj.candidate.candidate || JSON.stringify(obj.candidate);
          remoteCandList.push(cstr);
          const li = document.createElement('li'); li.textContent = cstr; remoteCandsEl.appendChild(li);
        }
        try { await pc.addIceCandidate(obj.candidate); } catch (e) { console.warn(e); }
      }
    }

    function endCall() {
      if (pc) { try { pc.close(); } catch {} pc = null; }
      if (aiPc) { try { aiPc.close(); } catch {} aiPc = null; aiActive = false; aiReturnedTrack = null; aiSessionPromise = null; }
      if (localStream) { localStream.getTracks().forEach(t => t.stop()); localStream = null; localEl.srcObject = null; }
      if (remoteStream) { remoteStream = null; remoteEl.srcObject = null; }
      startBtn.disabled = false; hangupBtn.disabled = true;
      setStatus('call ended');
      setAIState('idle');
    }

    async function escalateToRelay() {
      // Set global relay flag and attempt one restart (host/offerer side only)
      forceRelay = true;
      if (pc) { try { pc.close(); } catch {} pc = null; }
      setStatus('retry (relay only)');
      if (!isScanner) {
        // We are original offerer: rebuild and send new offer with iceRestart
        await getMic();
        const newPc = ensurePC();
        if (!currentSender) {
          const micTracks = localStream.getAudioTracks();
          originalTrack = micTracks[0];
          currentSender = newPc.addTrack(originalTrack, localStream);
        }
        let offer = await newPc.createOffer({ iceRestart: true, offerToReceiveAudio: true, offerToReceiveVideo: false });
        offer.sdp = tuneOpusSdp(offer.sdp);
        await newPc.setLocalDescription(offer);
        send('signal', { data: { sdp: newPc.localDescription } });
        setStatus('offer (relay) sent');
      } else {
        // Answerer: wait for new offer from peer; nothing else to do.
        console.log('[ice] relay escalation on answerer; awaiting new offer');
      }
    }

    // Manual (fallback) join
    joinBtn.onclick = async () => {
      room = roomEl.value.trim(); if (!room) return alert('enter room');
      await connectWS(); send('join', { room });
    };
    startBtn.onclick = startCall; // fallback manual
    hangupBtn.onclick = () => { send('leave'); endCall(); };

  // --------- QR Auto Flow ---------
  const roomParam = params.get('room');
    document.body.classList.add('auto-flow');
    if (roomParam) {
      room = roomParam; isScanner = true; flow.classList.add('hidden');
      autoJoinAndCall();
    } else {
      setupLanguageSelection();
    }

    function setupLanguageSelection() {
      langSelect.querySelectorAll('button[data-lang]').forEach(btn => {
        btn.onclick = () => { chosenLang = btn.dataset.lang; proceedCreateRoom(); };
      });
      enterScan.onclick = (e) => { e.preventDefault(); startScanning(); };
      cancelScanBtn.onclick = stopScanning;
    }

    async function proceedCreateRoom() {
      langSelect.classList.add('hidden');
      qrStage.classList.remove('hidden');
      langChosenEl.textContent = chosenLang === 'zh' ? '已选择: 中文 (Room Host)' : 'Selected: English (Room Host)';
      room = 'rm-' + Math.random().toString(36).slice(2, 10);
      const link = `${location.origin}${location.pathname}?room=${room}`;
      generateQR(link);
      qrMetaEl.textContent = link;
      await connectWS();
      send('join', { room });
      setStatus('waiting peer (show QR)');
    }

    async function autoJoinAndCall() {
      await connectWS();
      send('join', { room });
      setStatus('joined (auto)');
    }

    function generateQR(text) {
      // Use server-side endpoint to avoid CDN loading & nosniff issues
      qrEl.textContent = 'Generating QR…';
      fetch('/qr?text=' + encodeURIComponent(text))
        .then(r=> r.ok ? r.json() : Promise.reject(new Error('qr http '+r.status)))
        .then(({dataUrl}) => {
          if (!dataUrl) throw new Error('no dataUrl');
          qrEl.innerHTML='';
          const img = document.createElement('img');
          img.src = dataUrl; img.alt='QR'; img.style.width='256px'; img.style.height='256px'; img.style.borderRadius='12px';
          qrEl.appendChild(img);
        })
        .catch(e=>{ qrEl.textContent='QR error'; console.error(e); });
    }

    async function startScanning() {
      scanView.classList.add('active');
      enterScan.style.display='none';
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio:false });
        scanVideo.srcObject = stream; await scanVideo.play();
        scanLoop();
      } catch (e) {
        showToast('Camera error: '+e.message, 'error');
        stopScanning();
      }
    }
    function stopScanning() {
      scanView.classList.remove('active');
      enterScan.style.display='inline-block';
      if (scanVideo.srcObject) { scanVideo.srcObject.getTracks().forEach(t=>t.stop()); scanVideo.srcObject=null; }
    }
    async function scanLoop() {
      if (!scanView.classList.contains('active')) return; // cancelled
      const canvas = document.createElement('canvas');
      const v = scanVideo;
      if (v.readyState >= 2 && v.videoWidth) {
        canvas.width = v.videoWidth; canvas.height = v.videoHeight;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(v,0,0);
        if (barcodeDetector) {
          try {
            const bitmap = await createImageBitmap(canvas);
            const codes = await barcodeDetector.detect(bitmap);
            if (codes && codes.length) {
              const val = codes[0].rawValue;
              stopScanning();
              location.href = val;
              return;
            }
          } catch (e) { /* ignore transient */ }
        }
      }
      requestAnimationFrame(scanLoop);
    }
    function decodeQR(img) {
      // Try native BarcodeDetector first
      if (window.BarcodeDetector && decodeQR._bdReady) {
        // (unused path because we run detection outside) keep placeholder
      }
      // Fallback placeholder: return null (jsQR path removed for now)
      return null;
    }

    // Improved scanLoop using BarcodeDetector if available
    let barcodeDetector = null;
    if (window.BarcodeDetector) {
      try { barcodeDetector = new window.BarcodeDetector({ formats: ['qr_code'] }); decodeQR._bdReady = true; }
      catch(e){ console.warn('BarcodeDetector unavailable', e); }
    }

    // --- OpenAI Realtime conversion layer ---
    async function initializeRealtimeConversion(force=false) {
      if (!interpretChk.checked && !force) return; // disabled
      if (aiSessionPromise) return aiSessionPromise;
      if (!localStream || !currentSender) return;
      setAIState('connecting');
      aiSessionPromise = (async () => {
        try {
          const tokRes = await fetch('/openai-token');
          if (!tokRes.ok) throw new Error('ephemeral token fetch failed');
          const { token } = await tokRes.json();
          if (!token) throw new Error('no token');

          aiPc = new RTCPeerConnection();
          aiPc.onconnectionstatechange = () => {
            if (aiPc.connectionState === 'failed') setAIState('failed');
          };
          aiPc.ontrack = (e) => {
            const tracks = e.streams[0].getAudioTracks();
            if (!tracks.length) return;
            aiReturnedTrack = tracks[0];
            if (monitorChk.checked) {
              aiMonitorEl.srcObject = new MediaStream([aiReturnedTrack]);
            }
            if (interpretChk.checked && currentSender && !aiActive) {
              currentSender.replaceTrack(aiReturnedTrack).then(()=>{
                aiActive = true; setAIState('active'); setStatus('interpreted audio active');
                showToast('Interpretation active');
              }).catch(err => console.warn('replaceTrack error', err));
            }
          };
          localStream.getAudioTracks().forEach(t => aiPc.addTrack(t, localStream));
          const dc = aiPc.createDataChannel('oai-events');
          dc.onopen = () => {
            const systemPrompt = 'you are an native english simultaneous interpretation, your will interpretation as fast as possible, and rewording it in fluent english with high confidence.';
            try { dc.send(JSON.stringify({ type: 'response.create', response: { instructions: systemPrompt } })); }
            catch(e){ console.warn('prompt send failed', e); }
          };
          const offer = await aiPc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
          await aiPc.setLocalDescription(offer);
          const oaiRes = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17', {
            method: 'POST',
            body: aiPc.localDescription.sdp,
            headers: {'Authorization': 'Bearer '+token,'Content-Type': 'application/sdp'}
          });
          if (!oaiRes.ok) throw new Error('SDP exchange failed');
          const answerSdp = await oaiRes.text();
          await aiPc.setRemoteDescription({ type: 'answer', sdp: answerSdp });
          setAIState('waiting audio');
          setTimeout(()=>{ if (!aiActive) showToast('Still waiting for AI audio...', 'warn'); }, 5000);
          return true;
        } catch (e) {
          setAIState('failed');
          showToast('AI setup error: '+ e.message, 'error');
          aiSessionPromise = null;
          throw e;
        }
      })();
      return aiSessionPromise;
    }

    interpretChk?.addEventListener('change', () => {
      if (!currentSender || !localStream) return;
      if (interpretChk.checked) {
        setAIState('enabling');
        if (aiReturnedTrack && aiPc && aiPc.connectionState !== 'failed') {
          currentSender.replaceTrack(aiReturnedTrack).then(()=>{ aiActive = true; setAIState('active'); showToast('Interpretation enabled'); });
        } else {
          initializeRealtimeConversion().catch(()=>{});
        }
      } else {
        if (originalTrack && currentSender) {
          currentSender.replaceTrack(originalTrack).then(()=>{
            aiActive = false; setAIState('disabled'); showToast('Interpretation disabled');
          });
        }
      }
    });

    monitorChk?.addEventListener('change', () => {
      aiMonitorWrap.style.display = monitorChk.checked ? 'block' : 'none';
      if (monitorChk.checked) {
        if (aiReturnedTrack) aiMonitorEl.srcObject = new MediaStream([aiReturnedTrack]);
      } else {
        aiMonitorEl.srcObject = null;
      }
    });
  </script>
</body>
</html>
